#!/usr/bin/env python3
"""
Generate weekly digest of federal buyout news.
Compiles articles from the past week into a formatted report.
"""

import argparse
import json
import re
import smtplib
from datetime import datetime, timedelta
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from pathlib import Path

# Load articles database
DATA_DIR = Path(__file__).parent.parent / "data"
ARTICLES_FILE = DATA_DIR / "articles.json"


def load_articles():
    """Load tracked articles."""
    if ARTICLES_FILE.exists():
        with open(ARTICLES_FILE, 'r') as f:
            return json.load(f)
    return {}


def get_weekly_articles():
    """Get articles from past 7 days."""
    articles = load_articles()
    week_ago = datetime.now() - timedelta(days=7)
    
    weekly = []
    for url, art in articles.items():
        try:
            pub_date = datetime.fromisoformat(art['published'].replace('Z', '+00:00').replace('+00:00', ''))
            if pub_date >= week_ago:
                weekly.append(art)
        except:
            continue
    
    # Sort by score and date
    weekly.sort(key=lambda x: (x.get('score', 0), x.get('published', '')), reverse=True)
    return weekly


def generate_digest(articles):
    """Generate formatted weekly digest."""
    high_priority = [a for a in articles if a.get('score', 0) >= 70]
    medium_priority = [a for a in articles if 40 <= a.get('score', 0) < 70]
    other = [a for a in articles if a.get('score', 0) < 40]
    
    # Calculate date range
    dates = []
    for art in articles:
        try:
            dates.append(datetime.fromisoformat(art['published'].replace('Z', '+00:00').replace('+00:00', '')))
        except:
            continue
    
    if dates:
        start_date = min(dates).strftime('%B %d')
        end_date = max(dates).strftime('%B %d, %Y')
        date_range = f"{start_date} - {end_date}"
    else:
        date_range = "Past 7 Days"
    
    lines = [
        "# Federal Buyout Weekly Digest",
        f"## {date_range}",
        "",
        f"**Total Articles Tracked:** {len(articles)}",
        f"**High Priority:** {len(high_priority)} | **Medium Priority:** {len(medium_priority)} | **Other:** {len(other)}",
        "",
        "---",
        "",
    ]
    
    # High priority section
    if high_priority:
        lines.extend([
            "## ðŸš¨ High Priority News",
            "",
        ])
        for art in high_priority:
            lines.extend(format_article(art, detailed=True))
        lines.append("")
    
    # Medium priority section
    if medium_priority:
        lines.extend([
            "## ðŸ“° Medium Priority News",
            "",
        ])
        for art in medium_priority[:10]:  # Limit to top 10
            lines.extend(format_article(art, detailed=True))
        lines.append("")
    
    # Quick mentions
    if other:
        lines.extend([
            "## ðŸ“Ž Other Mentions",
            "",
        ])
        for art in other[:10]:
            lines.extend(format_article(art, detailed=False))
        lines.append("")
    
    # Summary stats
    lines.extend([
        "---",
        "",
        "## Summary",
        "",
    ])
    
    if articles:
        avg_score = sum(a.get('score', 0) for a in articles) / len(articles)
        sources = {}
        for art in articles:
            src = art.get('source', 'unknown')
            sources[src] = sources.get(src, 0) + 1
        
        lines.extend([
            f"- **Average Relevance Score:** {avg_score:.1f}/100",
            f"- **Most Active Source:** {max(sources.items(), key=lambda x: x[1])[0]}",
            "",
            "### Source Breakdown:",
        ])
        for src, count in sorted(sources.items(), key=lambda x: -x[1]):
            lines.append(f"- {src}: {count} articles")
    
    lines.extend([
        "",
        "---",
        "",
        "*Generated by FedBuyOut News Monitor*",
        f"*{datetime.now().strftime('%Y-%m-%d %H:%M UTC')}*"
    ])
    
    return '\n'.join(lines)


def format_article(art, detailed=False):
    """Format a single article entry."""
    lines = []
    
    title = art.get('title', 'Untitled')
    url = art.get('url', '')
    score = art.get('score', 0)
    source = art.get('source', 'Unknown')
    published = art.get('published', '')
    
    # Format date
    try:
        pub_date = datetime.fromisoformat(published.replace('Z', '+00:00').replace('+00:00', ''))
        date_str = pub_date.strftime('%b %d')
    except:
        date_str = 'Unknown date'
    
    if detailed:
        lines.extend([
            f"### [{title}]({url})",
            f"**Source:** {source} | **Score:** {score}/100 | **Date:** {date_str}",
            "",
        ])
        
        desc = art.get('description', '')
        if desc and len(desc) > 50:
            lines.append(f"{desc[:300]}{'...' if len(desc) > 300 else ''}")
            lines.append("")
    else:
        lines.append(f"- **[{title}]({url})** ({source}, {date_str})")
    
    return lines


def save_digest(content, output_path=None):
    """Save digest to file."""
    if output_path:
        path = Path(output_path)
    else:
        digest_dir = DATA_DIR / "digests"
        digest_dir.mkdir(exist_ok=True)
        filename = f"digest-{datetime.now().strftime('%Y-%m-%d')}.md"
        path = digest_dir / filename
    
    with open(path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    return path


def email_digest(content, to_email):
    """Email digest to recipient."""
    # Load environment variables
    from dotenv import load_dotenv
    import os
    
    load_dotenv(DATA_DIR.parent / '.env')
    
    # Try using Resend API
    api_key = os.getenv('RESEND_API_KEY')
    from_email = os.getenv('FROM_EMAIL', 'alerts@fedbuyout.com')
    
    if api_key:
        try:
            import requests
            
            response = requests.post(
                'https://api.resend.com/emails',
                headers={'Authorization': f'Bearer {api_key}'},
                json={
                    'from': f'FedBuyOut Alerts <{from_email}>',
                    'to': [to_email],
                    'subject': f'Weekly Federal Buyout Digest - {datetime.now().strftime("%b %d")}',
                    'html': markdown_to_html(content)
                }
            )
            
            if response.status_code == 200:
                print(f"Digest emailed to {to_email}")
                return True
            else:
                print(f"Email failed: {response.text}")
                return False
        except Exception as e:
            print(f"Email error: {e}")
            return False
    
    print("No RESEND_API_KEY found in .env")
    return False


def markdown_to_html(markdown):
    """Simple markdown to HTML conversion."""
    html = markdown
    
    # Headers
    html = re.sub(r'^### (.+)$', r'<h3>\1</h3>', html, flags=re.MULTILINE)
    html = re.sub(r'^## (.+)$', r'<h2>\1</h2>', html, flags=re.MULTILINE)
    html = re.sub(r'^# (.+)$', r'<h1>\1</h1>', html, flags=re.MULTILINE)
    
    # Bold
    html = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', html)
    
    # Links
    html = re.sub(r'\[(.+?)\]\((.+?)\)', r'<a href="\2">\1</a>', html)
    
    # Paragraphs
    paragraphs = html.split('\n\n')
    wrapped = []
    for p in paragraphs:
        if not p.startswith('<'):
            p = f'<p>{p}</p>'
        wrapped.append(p)
    
    return '<html><body>' + '\n'.join(wrapped) + '</body></html>'


def main():
    parser = argparse.ArgumentParser(description='Generate weekly digest')
    parser.add_argument('--output', '-o', help='Output file path')
    parser.add_argument('--email', '-e', help='Email address to send digest')
    parser.add_argument('--preview', action='store_true', help='Preview without saving')
    
    args = parser.parse_args()
    
    # Get weekly articles
    articles = get_weekly_articles()
    
    if not articles:
        print("No articles found from the past week")
        return
    
    # Generate digest
    digest = generate_digest(articles)
    
    if args.preview:
        print(digest)
    elif args.email:
        email_digest(digest, args.email)
        # Also save
        path = save_digest(digest, args.output)
        print(f"Digest saved to: {path}")
    else:
        path = save_digest(digest, args.output)
        print(f"Digest saved to: {path}")
        print(f"\n{len(articles)} articles included")


if __name__ == '__main__':
    main()
